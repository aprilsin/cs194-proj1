{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T00:42:14.950766Z",
     "start_time": "2020-09-10T00:42:14.827881Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: ./output/*: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T01:10:12.377063Z",
     "start_time": "2020-09-10T01:10:12.372636Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import glob\n",
    "import itertools\n",
    "import os\n",
    "import sys\n",
    "from copy import deepcopy\n",
    "from dataclasses import dataclass, field\n",
    "from functools import lru_cache, reduce\n",
    "from itertools import chain, product\n",
    "from skimage import img_as_float,img_as_ubyte\n",
    "from os import PathLike\n",
    "from pathlib import Path\n",
    "from typing import (Dict, Iterable, List, Mapping, NamedTuple, Optional,\n",
    "                    Sequence)\n",
    "import time\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import ndarray\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declarations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T00:42:16.598770Z",
     "start_time": "2020-09-10T00:42:16.592627Z"
    }
   },
   "outputs": [],
   "source": [
    "Channel = ndarray\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Pic:\n",
    "    red: Channel\n",
    "    blue: Channel\n",
    "    green: Channel\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Offset:\n",
    "    row: int\n",
    "    col: int\n",
    "\n",
    "    def __sub__(self, other: Offset) -> Offset:\n",
    "        return Offset(self.row - other.row, self.col - other.col)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Pixel:\n",
    "    row: int\n",
    "    col: int\n",
    "\n",
    "    def __add__(self, other: Offset) -> Pixel:\n",
    "        return Pixel(self.row + other.row, self.col + other.col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alignment Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T00:42:17.012416Z",
     "start_time": "2020-09-10T00:42:17.009029Z"
    }
   },
   "outputs": [],
   "source": [
    "def ssd(x: ndarray, y: ndarray) -> float:\n",
    "    return np.sum((x - y) ** 2)\n",
    "\n",
    "def gradient(x: ndarray, y: ndarray) -> float:\n",
    "    return ssd(cv2.Laplacian(x, cv2.CV_64F), cv2.Laplacian(y, cv2.CV_64F))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T00:42:17.193675Z",
     "start_time": "2020-09-10T00:42:17.183799Z"
    }
   },
   "outputs": [],
   "source": [
    "def initialize_pic(img: ndarray) -> Pic:\n",
    "    excess = len(img) % 3\n",
    "    if excess != 0:\n",
    "        img = img[:-excess]\n",
    "    b, g, r = np.split(img, indices_or_sections=3)\n",
    "    return Pic(red=r, blue=b, green=g)\n",
    "\n",
    "\n",
    "def calc_align_basic(\n",
    "    reference_img: Channel,\n",
    "    other: Channel,\n",
    "    metric: Callable = ssd,\n",
    "    offset_window: int = 15,\n",
    "    r_estim: int = 0,\n",
    "    c_estim: int = 0,\n",
    ") -> Offset:\n",
    "    \"\"\"Give best offset for alignment of 2 channels.\"\"\"\n",
    "    scores = {}\n",
    "\n",
    "    for r_off, c_off in product(range(-offset_window, offset_window + 1), repeat=2):\n",
    "        shifted = np.roll(other, shift=(r_estim + r_off, c_estim + c_off), axis=(0, 1))\n",
    "        scores[(r_estim + r_off, c_estim + c_off)] = metric(reference_img, shifted)\n",
    "\n",
    "    r_off, c_off = min(scores, key=lambda k: scores[k])\n",
    "    return Offset(r_off, c_off)\n",
    "\n",
    "def shift_2d_replace(data, offset: Offset, constant=0):\n",
    "    \"\"\"Shifts the array in two dimensions while setting rolled values to\n",
    "    constant.\n",
    "\n",
    "    :param data: The 2d numpy array to be shifted\n",
    "    :param dx: The shift in x\n",
    "    :param dy: The shift in y\n",
    "    :param constant: The constant to replace rolled values with\n",
    "    :return: The shifted array with \"constant\" where roll occurs\n",
    "    \"\"\"\n",
    "    dx, dy = offset.col, offset.row\n",
    "\n",
    "    shifted_data: ndarray = np.roll(data, dx, axis=1)\n",
    "    if dx < 0:\n",
    "        shifted_data[:, dx:] = constant\n",
    "    elif dx > 0:\n",
    "        shifted_data[:, 0:dx] = constant\n",
    "\n",
    "    shifted_data = np.roll(shifted_data, dy, axis=0)\n",
    "    if dy < 0:\n",
    "        shifted_data[dy:, :] = constant\n",
    "    elif dy > 0:\n",
    "        shifted_data[0:dy, :] = constant\n",
    "    return shifted_data\n",
    "\n",
    "\n",
    "def merge(pic: Pic) -> ndarray:\n",
    "    \"\"\"Combine all channels into PIL Image.\"\"\"\n",
    "    merged = np.stack([pic.red, pic.green, pic.blue], axis=-1)\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T00:42:17.392591Z",
     "start_time": "2020-09-10T00:42:17.383780Z"
    }
   },
   "outputs": [],
   "source": [
    "def calc_align_pyramid(to_align: Channel, ref: Channel) -> Channel:\n",
    "    \"\"\"Aligns two channels using image pyramids.\"\"\"\n",
    "    THRESHOLD = 800\n",
    "    print(to_align.size, to_align.shape)\n",
    "    if to_align.size < THRESHOLD ** 2 and ref.size < THRESHOLD ** 2:\n",
    "        return calc_align_basic(to_align, ref)\n",
    "    to_align_resized = cv2.resize(\n",
    "        src=to_align, dsize=(to_align.shape[0] // 2, to_align.shape[1] // 2)\n",
    "    )\n",
    "    ref_resized = cv2.resize(src=ref, dsize=(ref.shape[0] // 2, ref.shape[1] // 2))\n",
    "    estim_Offset = calc_align_pyramid(to_align_resized, ref_resized)\n",
    "    corr_Offset = Offset(row=estim_Offset.row * 2, col=estim_Offset.col * 2)\n",
    "\n",
    "    return corr_Offset\n",
    "#   return calc_align_basic(    ref, to_align, r_estim=corr_Offset.row, c_estim=corr_Offset.col, offset_window=2)\n",
    "\n",
    "\n",
    "def align_pic_basic(pic: Pic) -> (Pic, Offset, Offset):\n",
    "    \"\"\"Aligns aii three channels.\"\"\"\n",
    "    return align_pic(pic, calc_align_basic)\n",
    "\n",
    "\n",
    "def align_pic_with_pyramid(pic: Pic) -> (Pic, Offset, Offset):\n",
    "    \"\"\"Aligns aii three channels.\"\"\"\n",
    "    return align_pic(pic, calc_align_pyramid)\n",
    "\n",
    "\n",
    "def merge(pic: Pic) -> ndarray:\n",
    "    \"\"\"Combine all channels into PIL Image.\"\"\"\n",
    "    merged = np.stack([pic.red, pic.green, pic.blue], axis=-1)\n",
    "    return merged\n",
    "\n",
    "\n",
    "def align_pic(\n",
    "    pic: Pic, calc_align: Callable, align_metric: Callable = gradient\n",
    ") -> (Pic, Offset, Offset):\n",
    "    \"\"\"Aligns all three channels.\"\"\"\n",
    "    # align red\n",
    "    r_offset = calc_align(pic.blue, pic.red)\n",
    "    r = shift_2d_replace(pic.red, r_offset)\n",
    "    # align green\n",
    "    g_offset = calc_align(pic.blue, pic.green)\n",
    "    g = shift_2d_replace(pic.green, g_offset)\n",
    "    return Pic(blue=pic.blue, red=r, green=g), r_offset, g_offset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjustments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T00:42:17.754180Z",
     "start_time": "2020-09-10T00:42:17.750589Z"
    }
   },
   "outputs": [],
   "source": [
    "def fix_exposure(x: ndarray, show=False):\n",
    "    unit_len = np.max(x) - np.min(x)\n",
    "    fixed = (x - np.amin(x)) / unit_len\n",
    "    if show:\n",
    "        plt.imshow(fixed)\n",
    "    return fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T00:42:17.919555Z",
     "start_time": "2020-09-10T00:42:17.914313Z"
    }
   },
   "outputs": [],
   "source": [
    "def awb_grey(im: ndarray, show=False):\n",
    "    # Compute the mean color over the entire image\n",
    "    avg_color = np.mean(im)\n",
    "\n",
    "    # Scale the averge color to be grey (0.5)\n",
    "    scaling = 0.5 / avg_color\n",
    "\n",
    "    # Apply the scaling to the entire image\n",
    "    balanced_im = im * scaling\n",
    "    #balanced_im = balanced_im.astype(np.uint8)\n",
    "    if show:\n",
    "        plt.imshow(balanced_im)\n",
    "    return balanced_im\n",
    "\n",
    "def awb_white(im: ndarray, show=False):\n",
    "    # Compute the brightest color over the entire image\n",
    "    brightest_color = np.amax(im)\n",
    "\n",
    "    # Scale the brightest color to be white (1.0)\n",
    "    scaling = 1.0 / brightest_color\n",
    "\n",
    "    # Apply the scaling to the entire image\n",
    "    balanced_im = im * scaling\n",
    "    #balanced_im = balanced_im.astype(np.uint8)\n",
    "    if show:\n",
    "        plt.imshow(balanced_im)\n",
    "    return balanced_im\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T00:42:18.112921Z",
     "start_time": "2020-09-10T00:42:18.102541Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_borders(mat) -> (int, int):\n",
    "    val_r, val_c = [], []\n",
    "    val_rs, val_cs = [], []\n",
    "    R, C = mat.shape\n",
    "    sobel_c = cv2.Sobel(mat,cv2.CV_64F,1,0,ksize=5)\n",
    "    sobel_r = cv2.Sobel(mat,cv2.CV_64F,0,1,ksize=5)\n",
    "    \n",
    "    # find row border\n",
    "    for i in range(R):\n",
    "        val_r.append(mat[i] @ mat[i - 1])\n",
    "        val_rs.append(sobel_r[i] @ sobel_r[i - 1])\n",
    "    r_up_cutoff = (np.argmin(val_r[R//20:R//4]) + np.argmin(val_rs[R//20:R//4])) // 2\n",
    "    r_bot_cutoff = (np.argmin(val_r[R//4*3:-R//15]) + np.argmin(val_r[R//4*3:-R//20])) // 2\n",
    "                              \n",
    "    # find col border\n",
    "    for i in range(C):\n",
    "        val_c.append(sobel_c[:, i] @ sobel_c[:, i - 1])\n",
    "    c_left_cutoff = np.argmin(val_c[C//20:C//4])\n",
    "    c_right_cutoff = np.argmin(val_c[C//4*3:-C//20])\n",
    "    return r_up_cutoff, r_bot_cutoff, c_left_cutoff, c_right_cutoff\n",
    "\n",
    "def crop_borders(pic:Pic):\n",
    "    r_up_cut, r_bot_cut, r_left_cut, r_right_cut = find_borders(pic.red)\n",
    "    g_up_cut, g_bot_cut, g_left_cut, g_right_cut = find_borders(pic.green)\n",
    "    b_up_cut, b_bot_cut, b_left_cut, b_right_cut = find_borders(pic.blue)\n",
    "    \n",
    "    up_cut = int(np.mean([r_up_cut, g_up_cut, b_up_cut]))\n",
    "    bot_cut = int(np.mean([r_bot_cut, g_bot_cut, b_bot_cut]))\n",
    "    left_cut = int(np.mean([r_left_cut, g_left_cut, b_left_cut]))\n",
    "    right_cut = int(np.mean([r_right_cut, g_right_cut, b_right_cut]))\n",
    "    \n",
    "    pic.red = pic.red[up_cut:bot_cut, left_cut:right_cut]\n",
    "    pic.green = pic.green[up_cut:bot_cut, left_cut:right_cut]\n",
    "    pic.blue = pic.blue[up_cut:bot_cut, left_cut:right_cut]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T00:52:22.708464Z",
     "start_time": "2020-09-10T00:52:22.703611Z"
    }
   },
   "outputs": [],
   "source": [
    "def edge_detection(mat):\n",
    "    mat_edges = cv2.Canny(mat,80,180)\n",
    "    return mat_edges\n",
    "\n",
    "\n",
    "def align_pic_with_canny(\n",
    "    pic: Pic, calc_align: Callable=calc_align_pyramid, align_metric: Callable = gradient\n",
    ") -> (Pic, Offset, Offset):\n",
    "    \"\"\"Aligns all three channels.\"\"\"\n",
    "\n",
    "    r_edges = edge_detection(pic.red)\n",
    "    g_edges = edge_detection(pic.green)\n",
    "    b_edges = edge_detection(pic.blue)\n",
    "    \n",
    "    # align red\n",
    "    r_offset = calc_align(b_edges, r_edges)\n",
    "    r = shift_2d_replace(pic.red, r_offset)\n",
    "    \n",
    "    # align green\n",
    "    g_offset = calc_align(b_edges, g_edges)\n",
    "    g = shift_2d_replace(pic.green, g_offset)\n",
    "    \n",
    "    return Pic(blue=pic.blue, red=r, green=g), r_offset, g_offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T00:52:22.935204Z",
     "start_time": "2020-09-10T00:52:22.931391Z"
    }
   },
   "outputs": [],
   "source": [
    "def adjust(pic:Pic):\n",
    "    #crop_borders(pic)\n",
    "    pic.red = awb_grey(pic.red)\n",
    "    pic.green = awb_grey(pic.green)\n",
    "    pic.blue = awb_grey(pic.blue)\n",
    "    pic.red = fix_exposure(pic.red)\n",
    "    pic.green = fix_exposure(pic.green)\n",
    "    pic.blue = fix_exposure(pic.blue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T09:02:06.686028Z",
     "start_time": "2020-09-09T09:02:06.676265Z"
    }
   },
   "source": [
    "## Compute and Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T01:10:17.537780Z",
     "start_time": "2020-09-10T01:10:17.532963Z"
    }
   },
   "outputs": [],
   "source": [
    "def main(p: os.PathLike, f_out) -> None:\n",
    "    out_dir = Path(\"output\")\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    img_path = Path(p)\n",
    "    \n",
    "    # read image\n",
    "    img = img_as_float(plt.imread(img_path))\n",
    "\n",
    "    # initialize and adjust pictures\n",
    "    pic = initialize_pic(img)\n",
    "    adjust(pic)\n",
    "    aligned_pic = pic\n",
    "    red_offset, green_offset = Offset(), Offset()\n",
    "    \n",
    "    # comment out all alignments for direct stack\n",
    "    \n",
    "    # do alignments\n",
    "    #aligned_pic, red_offset, green_offset = align_pic_basic(pic)\n",
    "    #aligned_pic, red_offset, green_offset = align_pic_with_pyramid(pic)\n",
    "    \n",
    "\"\"\" comment/uncomment below for canny edge detection \"\"\"\n",
    "#     pic.red = img_as_ubyte(pic.red)\n",
    "#     pic.green = img_as_ubyte(pic.green)\n",
    "#     pic.blue = img_as_ubyte(pic.blue)\n",
    "#     aligned_pic, red_offset, green_offset = align_pic_with_canny(pic)\n",
    "\"\"\" comment/uncomment above for canny edge detection \"\"\"\n",
    "    \n",
    "    aligned_img = merge(aligned_pic)\n",
    "    aligned_img = Image.fromarray(img_as_ubyte(aligned_img))\n",
    "    aligned_img.save(out_dir / img_path.stem, arr=aligned_img, format=\"jpeg\", optimize=True, quality=50)\n",
    "    print(red_offset, green_offset, file=f_out)\n",
    "    \n",
    "    # plt.figure()\n",
    "    # plt.imshow(aligned_img)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T01:10:21.734839Z",
     "start_time": "2020-09-10T01:10:21.615281Z"
    }
   },
   "outputs": [],
   "source": [
    "!rm ./output/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T01:10:22.312654Z",
     "start_time": "2020-09-10T01:10:22.215398Z"
    }
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    data = Path(\"data\")\n",
    "    fname = 'offset_low.txt'\n",
    "    f_out = open(fname, 'w')\n",
    "    original_stdout = sys.stdout # Save a reference to the original standard output\n",
    "    sys.stdout = f_out # Change the standard output to the file we created.\n",
    "    t = time.time()\n",
    "    \n",
    "    for p in chain(data.rglob(\"*.jpg\")):\n",
    "        print(p, file=f_out)\n",
    "        main(p, f_out)\n",
    "    t = time.time() - t \n",
    "    print(f'\"rumtime is {t} seconds\"', file=f_out)\n",
    "    f_out.close()\n",
    "    sys.stdout = original_stdout # Reset the standard output to its original value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T01:10:46.123847Z",
     "start_time": "2020-09-10T01:10:23.175353Z"
    }
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    data = Path(\"data\")\n",
    "    fname = 'offset_high.txt'\n",
    "    f_out = open(fname, 'w')\n",
    "    original_stdout = sys.stdout # Save a reference to the original standard output\n",
    "    sys.stdout = f_out # Change the standard output to the file we created.\n",
    "    t = time.time()\n",
    "        \n",
    "    for p in chain(data.rglob(\"*.tif\")):\n",
    "        print(p, file=f_out)\n",
    "        main(p, f_out)\n",
    "    t = time.time() - t \n",
    "    print(f'\"rumtime is {t} seconds\"', file=f_out)\n",
    "    f_out.close()\n",
    "    sys.stdout = original_stdout # Reset the standard output to its original value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
